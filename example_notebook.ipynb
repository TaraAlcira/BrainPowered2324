{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Introduction notebook Brainpowered course</h1>\n",
    "\n",
    "This notebook is an introductionary notebook for the course Brainpowered. In this notebook some basic data analysis on EEG data will be done. Also some data preprocessing will be done in the form of a bandwidth and notch filter will be done. At last some classification methods such as Knn (K nearest neighbors), SVM (Support Vector Machines) and LDA (Linear Discriminant Analysis). The EEG data used in this notebook is data of people who keep their eyes closed or open for a period of 10 seconds. So the classification methods are used to classify if a person has their eyes closed or open.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your own imports if needed\n",
    "import os\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "from collections import defaultdict\n",
    "from mne.decoding import CSP\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of contents:\n",
    "* [Dataset](#dataset)\n",
    "* [Making your first plots](#first_plot)\n",
    "* [EEG preprocessing](#preprocessing)\n",
    "* [Spectral analysis](#spectrum)\n",
    "* [Analyze the two classes](#two_classes)\n",
    "* [Feature extraction](#feature)\n",
    "* [Classification of the two classes](#classification)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Dataset</h2> <a class=\"dataset\" id=\"dataset\"></a>\n",
    "During this fase, we will look at the dataset. First we load the file and look at the data. The data is stored in a .mat file. This is a file format used by Matlab. We can load this file using the scipy.io library. This library is used to load matlab files. The data is stored in a dictionary. The keys of the dictionary are the names of the variables in the matlab file. The values of the dictionary are the values of the variables in the matlab file. \n",
    "\n",
    "It is important to look at the dataset before you start analyzing it. This way you know what you are working with. You can look at the shape of the data, the type of the data and the values of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = 'data_alpha/'\n",
    "\n",
    "# Get the list of subjects in the data, and sort the list\n",
    "subject_files = os.listdir(data_directory)\n",
    "subject_files.sort()\n",
    "\n",
    "# What is the structure of one .mat file?\n",
    "print(scipy.io.loadmat(data_directory + subject_files[0]))\n",
    "\n",
    "# What is the shape of the data matrix?\n",
    "print(scipy.io.loadmat(data_directory + subject_files[0])[\"SIGNAL\"].shape)\n",
    "\n",
    "# the channel names (in order)\n",
    "channel_names = ['Fp1', 'Fp2', 'Fc5', 'Fz', 'Fc6', 'T7', 'Cz', 'T8', 'P7', 'P3', 'Pz', 'P4','P8', 'O1', 'Oz', 'O2']\n",
    "\n",
    "# the number of channels\n",
    "n_channels = len(channel_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Making your first plots</h2> <a class=\"first_plot\" id=\"first_plot\"></a>\n",
    "To get an idea about what the data looks like, plotting the data is a good way to do this. But first we choose the subject, and search for the data of that subject in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the subject to analyze\n",
    "nth_subject = 2\n",
    "subject = subject_files[nth_subject]\n",
    "\n",
    "# now load the data from the chosen subject\n",
    "subject_matrix = scipy.io.loadmat(data_directory + subject)[\"SIGNAL\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make a simple plot of our data, we use the matplotlib library. This library is used to make plots. We can plot the data using the plot function. The plot function takes two arguments, the x values and the y values. The x values are the time values and the y values are the micro voltage values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# condition 1: eyes are closed\n",
    "condition_1 = subject_matrix[:, 17]\n",
    "\n",
    "# find the indices where condition 1 is 1\n",
    "idx_condition_1 = np.where(condition_1 == 1)[0]\n",
    "\n",
    "\n",
    "# condition 2: eyes are open\n",
    "condition_2 = subject_matrix[:, 18]\n",
    "\n",
    "# find the indices where condition 2 is 1\n",
    "idx_condition_2 = np.where(condition_2 == 1)[0]\n",
    "\n",
    "\n",
    "# start from when the first condition is measured\n",
    "start_idx = idx_condition_1[0]\n",
    "time_stamps = subject_matrix[start_idx:, 0]\n",
    "eeg_measurements = subject_matrix[start_idx:, 1:17]\n",
    "\n",
    "# plot the EEG measurements of each person in different plots,\n",
    "# where the subplots are the waves from the electrodes of one person\n",
    "fig, axs = plt.subplots(n_channels, sharex=True)\n",
    "\n",
    "# adjust sizes of plot\n",
    "fig.set_figheight(30)\n",
    "fig.set_figwidth(20)\n",
    "plt.subplots_adjust(hspace=1.0)\n",
    "print(f\"{subject} EEG measurements raw data\")\n",
    "\n",
    "\n",
    "# plot each channel in a separate subplot\n",
    "for nth_channel in range(n_channels):\n",
    "    axs[nth_channel].plot(time_stamps, eeg_measurements[:, nth_channel])\n",
    "    axs[nth_channel].set_title(channel_names[nth_channel])\n",
    "\n",
    "for ax in axs.flat:\n",
    "    ax.set(xlabel='Timestamps', ylabel='Voltage (uV)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>EEG preprocessing</h2> <a class=\"preprocessing\" id=\"preprocessing\"></a>\n",
    "\n",
    "EEG preprocessing is important. EEG is a non-invasive method, so there will be many artifacts in the data. There are two types of preprocessing steps There are many preprocessing methods, but in this notebook we will keep it simple. The preprocessing steps used in this notebook are first filtering our EEG data with a notch and a bandpass filter. The notch filter is used to filter out the 50 Hz frequency which is caused by the electronics around you. The bandpass filter will be used to filter the alpha band, which is from around 8-14 Hz. These preprocessing steps can also be used during the real time flying of the drone with your own EEG data. But another preprocessing step which can be done before choosing which channels you want to measure with EEG is removal of faulty channels. We will do this preprocessing step later on in the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When applying functions/filters on your EEG data it is important to know what sampling rate your EEG data is. Otherwise the function/filter can behave in unexpected ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the sampling frequency used for this specific dataset\n",
    "fs = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will make the notch filter for the 50 Hz artifact in EEG data. This will remove the 50 Hz and its harmonics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequency you want to remove\n",
    "f_notch = 50\n",
    "# the quality factor of the notch filter\n",
    "Q = 30\n",
    "# also in this function always give your sampling frequency to the function\n",
    "b, a = signal.iirnotch(f_notch, Q, fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When somoeone has their eyes closed the alpha wave is likely to occur in the EEG. This peak is between 8-13 Hz. So our bandpass filter will only let these frequency bands through. The parameters you need to give to the butter filter is N which is the order. The filter order controls how sharply it separates the bandpass from the stop band. So after you applied the filter and made the spectrum plots see what happens if you change this value. The higher the order the longer the filter takes. The Wn parameter is an array with the critical frequencies, if you give your sampling frequency to this function signal.butter will normalize these critical frequencies based on the sampling frequency given as input. Otherwise the filter will behave unexpectedly. The btype parameter is the type of the filter which is bandpass. Output is sos which is used for general-purpose filtering. The fs is the sampling frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sos = signal.butter(N=10, Wn=[8, 15], btype=\"bandpass\", output=\"sos\", fs=fs)\n",
    "# print the filter to see how it changes with the order\n",
    "print(sos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After these filters are applied on the channels the channels can be plotted to see how they look after filtering. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_matrix = scipy.io.loadmat(data_directory + subject)[\"SIGNAL\"]\n",
    "\n",
    "condition_1 = subject_matrix[:, 17]\n",
    "idx_condition_1 = np.where(condition_1 == 1)[0]\n",
    "condition_2 = subject_matrix[:, 18]\n",
    "idx_condition_2 = np.where(condition_2 == 1)[0]\n",
    "\n",
    "# the timestamps from the start of condition 1 are taken, because from there the\n",
    "# first task has started\n",
    "time_stamps = subject_matrix[idx_condition_1[0]:, 0]\n",
    "# columns 1-16 are the columns with the EEG data\n",
    "eeg_measurements = subject_matrix[idx_condition_1[0]:, 1:17]\n",
    "\n",
    "fig, axs = plt.subplots(n_channels, sharex=True)\n",
    "fig.set_figheight(30)\n",
    "fig.set_figwidth(20)\n",
    "plt.subplots_adjust(hspace=1.0)\n",
    "plt.title(f\"Different channels EEG data {subject} after applying a notch and bandpass filter\")\n",
    "print(f\"{subject} EEG measurements filtered data\")\n",
    "\n",
    "for nth_channel in range(n_channels):\n",
    "    # filter the eeg measurement for the channel separately\n",
    "    filtered_eeg = signal.sosfilt(sos, eeg_measurements[:, nth_channel])\n",
    "\n",
    "    # plot the filtered eeg signal\n",
    "    axs[nth_channel].plot(time_stamps[idx_condition_1[0]:], filtered_eeg[idx_condition_1[0]:])\n",
    "    axs[nth_channel].set_title(channel_names[nth_channel])\n",
    "\n",
    "for ax in axs.flat:\n",
    "    ax.set(xlabel='Timestamps', ylabel='Voltage (uV)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the milivolt amplitude changes based on the filter. Also the data is more centered around zero. This doesn't really show what the filters achieved. For that we need to look at the spectrums. Which will be done in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The helper function below can be used to extract columns from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a helper function to extract different columns from the data\n",
    "def extract_columns(filename, path_to_file):\n",
    "    '''\n",
    "        Function to extract the columns from the .mat file of a subject\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        filename : str\n",
    "            The filename of the person you want to extract the columns from.\n",
    "        path_to_file : str\n",
    "            The path to where the .mat file is stored.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        idx_condition_1 : arr\n",
    "            The array with indices for condition 1.\n",
    "        idx_condition_2 : arr\n",
    "            The array with indices for condition 2.\n",
    "        time_stamps : arr\n",
    "            Array with the timestamps of the measurements.\n",
    "        eeg_measurements : ndarray\n",
    "            A matrix where each channel is an electrode of the EEG and the\n",
    "            rows are the measurements.\n",
    "    '''\n",
    "\n",
    "    subject_data = scipy.io.loadmat(path_to_file + filename)[\"SIGNAL\"]\n",
    "    # condition 1 is in column 17\n",
    "    condition_1 = subject_data[:, 17]\n",
    "    # index for starting row of condition 1\n",
    "    idx_condition_1 = np.where(condition_1 == 1)[0]\n",
    "    # condition 2 is in column 18\n",
    "    condition_2 = subject_data[:, 18]\n",
    "    # index for starting row of condition 1\n",
    "    idx_condition_2 = np.where(condition_2 == 1)[0]\n",
    "\n",
    "    time_stamps = subject_data[:, 0]\n",
    "    eeg_measurements = subject_data[:, 1:17]\n",
    "\n",
    "    return (idx_condition_1, idx_condition_2, time_stamps, eeg_measurements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we look at the spectra we first need to separate the trials of the different classes. Above we plotted the whole recording (except for the timestamps before condition 1), but our scope is to classify if someone has their eyes closed (condition 1) or open (condition 2). So another step in the preprocessing is the data prepartion where we will store the data of the different classes in a dictionary/other datastructure of your choice. Each block of the measurements consisted of 10 seconds (which can be read on the website) of recorder EEG data and 10 blocks were measured, so 10 trials. With the sample frequency which is 512 samples per second we can calculate that the next 10 * 512 samples (indices in our array) are part of the block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the trial you want to visualize because otherwise there will be too\n",
    "# many plots (for training you will use all trials)\n",
    "nth_trial = 0\n",
    "\n",
    "# These are the channels used in the analysis. Change them to experiment and see\n",
    "# which channels are the best for this specific task and data\n",
    "channel_names = ['Fp1', 'Fp2', 'Fc5', 'Fz', 'Fc6', 'T7', 'Cz', 'T8', 'P7', 'P3', 'Pz', 'P4','P8', 'O1', 'Oz', 'O2']\n",
    "# channel_names = ['Fp1', 'Fp2', 'Fc5', 'Fz', 'Fc6', 'T7', 'Cz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the data and different columns of the specified subject stored in the variable \"subject\"\n",
    "idx_condition_1, idx_condition_2, time_stamps, eeg_measurements = extract_columns(subject, data_directory)\n",
    "\n",
    "# initialize all the dictionaries. With default dict you don't need to check if\n",
    "# the key already exists, so less if statements\n",
    "# the key of this dictionary will be the channel name and after that the different\n",
    "# trials are appended, so the structure of the dictionaries will be:\n",
    "# {channel_name1 : [trial1, trial2,..., trialn], channel_name2 : [trial1,...,trialn]}\n",
    "condition_1_raw = defaultdict(lambda: [])\n",
    "condition_2_raw = defaultdict(lambda: [])\n",
    "condition_1_filt = defaultdict(lambda: [])\n",
    "condition_2_filt = defaultdict(lambda: [])\n",
    "\n",
    "length_measured_block = 10 # in seconds\n",
    "\n",
    "for nth_channel in range(len(channel_names)):\n",
    "\n",
    "    channel_data = eeg_measurements[:, nth_channel]\n",
    "\n",
    "    for idx_1, idx_2 in zip(idx_condition_1, idx_condition_2):\n",
    "        # add the + 1 because of how slicing works\n",
    "        condition_1_raw[channel_names[nth_channel]].append(channel_data[idx_1:idx_1 + fs * length_measured_block + 1])\n",
    "        condition_1_filt[channel_names[nth_channel]].append(signal.lfilter(b, a, signal.sosfilt(sos, channel_data)[idx_1:idx_1 + fs * length_measured_block + 1]))\n",
    "\n",
    "        condition_2_raw[channel_names[nth_channel]].append(channel_data[idx_2:idx_2 + fs * length_measured_block + 1])\n",
    "        condition_2_filt[channel_names[nth_channel]].append(signal.lfilter(b, a, signal.sosfilt(sos, channel_data)[idx_2:idx_2 + fs * length_measured_block + 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the shape of the data:\n",
    "# the first dimension is the number of trials, the second dimension is the amount of datapoints\n",
    "print(np.shape(condition_1_raw[channel_names[0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Spectral analysis</h2> <a class=\"spectrum\" id=\"spectrum\"></a>\n",
    "\n",
    "In this notebook we will plot the spectrums in two kind of ways. With the use of the FFT and Welch's method. FFT is the most standard way to make a spectral decomposition of the data, but because EEG data is non-stationary it won't show the spectrums as smooth. So that is why we will also look at the spectrum made with Welch's method. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FFT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Fast Fourier Transform (FFT) is used to transform EEG data from the time domain to the frequency domain, so we can look at frequencies present in the EEG data. This means that the raw signal is being decomposed into sinusoids of different frequencies. The frequency bands are an important feature in EEG data, which means that the FFT is an important tool to use in EEG data analysis. We will use the fft functions from numpy. The function which returns the frequencies returns positive and negative frequencies, which arises from the mathematics of the Fourier transform. We are only interested in the magnitude of the frequency components, so that is why we will filter to get only the positive frequencies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To show the result of the FFT we will plot the EEG data of the nth trial of the specified person, filtered (FFT) vs. unfiltered (raw):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(len(channel_names), 2, figsize=(15, 3 *len(channel_names)))\n",
    "for i, channel in enumerate(channel_names):\n",
    "\n",
    "    len_data = len(condition_1_raw[channel][nth_trial])\n",
    "    fft_vals = np.fft.fft(condition_1_raw[channel][nth_trial])\n",
    "    fft_freqs = np.fft.fftfreq(len_data, 1/fs)\n",
    "\n",
    "    # take only the positive values of the fft\n",
    "    positive_freq_mask = fft_freqs > 0\n",
    "    fft_freqs = fft_freqs[positive_freq_mask]\n",
    "    fft_vals = fft_vals[positive_freq_mask]\n",
    "\n",
    "    axs[i, 0].plot(fft_freqs, np.abs(fft_vals))\n",
    "\n",
    "    len_data = len(condition_2_raw[channel][nth_trial])\n",
    "    fft_vals = np.fft.fft(condition_2_raw[channel][nth_trial])\n",
    "    fft_freqs = np.fft.fftfreq(len_data, 1/fs)\n",
    "    # take only the positive values of the fft\n",
    "    positive_freq_mask = fft_freqs > 0\n",
    "    fft_freqs = fft_freqs[positive_freq_mask]\n",
    "    fft_vals = fft_vals[positive_freq_mask]\n",
    "\n",
    "    axs[i, 0].plot(fft_freqs, np.abs(fft_vals))\n",
    "\n",
    "    axs[i, 0].set_xlim(0, 80)\n",
    "    axs[i, 0].set_title(channel)\n",
    "\n",
    "\n",
    "    len_data = len(condition_1_filt[channel][nth_trial])\n",
    "    fft_vals = np.fft.fft(condition_1_filt[channel][nth_trial])[:len_data//2]\n",
    "    # take the last half of the data where there are only possible values (this\n",
    "    # didnt work with the raw data)\n",
    "    fft_freqs = np.fft.fftfreq(len_data, 1/fs)[:len_data//2]\n",
    "\n",
    "    axs[i, 1].plot(fft_freqs, np.abs(fft_vals))\n",
    "    len_data = len(condition_2_filt[channel][nth_trial])\n",
    "    fft_vals = np.fft.fft(condition_2_filt[channel][nth_trial])[:len_data//2]\n",
    "    fft_freqs = np.fft.fftfreq(len_data, 1/fs)[:len_data//2]\n",
    "\n",
    "    axs[i, 1].plot(fft_freqs, np.abs(fft_vals))\n",
    "    axs[i, 1].set_xlim(0, 60)\n",
    "    axs[i, 1].set_title(channel)\n",
    "\n",
    "for ax in axs.flat:\n",
    "    ax.set(xlabel='Frequencies (Hz)', ylabel='Amplitude')\n",
    "\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Welch's method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welch's method is an approach to estimate the power spectral density (PSD) of a signal. The PSD is the distribution of power into frequency components. Welch's method reduces noise in the estimated power spectra over the standard periodogram spectrum, but does reduce the frequency resolution. The obtained PSD can be used as a feature in the classification of the EEG data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(len(channel_names), 2, figsize=(15, 3 *len(channel_names)))\n",
    "\n",
    "for i, channel in enumerate(channel_names):\n",
    "    freqs, psd = signal.welch(condition_1_raw[channel][nth_trial], fs=fs)\n",
    "    axs[i, 0].plot(freqs, psd, label=\"eyes closed\")\n",
    "    freqs, psd = signal.welch(condition_2_raw[channel][nth_trial], fs=fs)\n",
    "    axs[i, 0].plot(freqs, psd, label=\"eyes open\")\n",
    "    axs[i, 0].set_title(\"raw \" + channel)\n",
    "    axs[i, 0].set_xlim(0, 100)\n",
    "\n",
    "    freqs, psd = signal.welch(condition_1_filt[channel][nth_trial], fs=fs)\n",
    "    axs[i, 1].plot(freqs, psd, label=\"eyes closed\")\n",
    "    freqs, psd = signal.welch(condition_2_filt[channel][nth_trial], fs=fs,)\n",
    "    axs[i, 1].plot(freqs, psd, label=\"eyes open\")\n",
    "    axs[i, 1].set_title(\"filt \" + channel)\n",
    "    axs[i, 1].set_xlim(0, 70)\n",
    "\n",
    "\n",
    "for ax in axs.flat:\n",
    "    ax.set(xlabel='Frequencies (Hz)', ylabel='Amplitude')\n",
    "\n",
    "\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Feature extraction</h2> <a class=\"feature\" id=\"feature\"></a>\n",
    "\n",
    "There are multiple features that can be extracted from EEG data. We will use CSP. \n",
    "\n",
    "The goal of CSP is to find a set of spatial filters that can effectively differentiate between two classes of signals based on their covariance matrices. The CSP algorithm is a supervised algorithm, which means that it needs labeled data to train the algorithm. The algorithm will then find a set of spatial filters that can differentiate between the two classes. The algorithm will find a set of spatial filters that will maximize the variance of one class and minimize the variance of the other class. This process results in new features (components) that are linear combinations of the original channels. The goal of the spatial filter is to find a set of spatial weights that maximally discriminate between two or more classes of EEG data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because this dataset contained only ten trials for each person we will do the CSP feature extraction on all the subjects. But this way can be easily translated to one person."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_1_raw = defaultdict(lambda: [])\n",
    "condition_2_raw = defaultdict(lambda: [])\n",
    "condition_1_filt = defaultdict(lambda: [])\n",
    "condition_2_filt = defaultdict(lambda: [])\n",
    "\n",
    "\n",
    "for subject in subject_files:\n",
    "    idx_condition_1, idx_condition_2, time_stamps, eeg_measurements = extract_columns(subject, data_directory)\n",
    "\n",
    "    for nth_channel in range(len(channel_names)):\n",
    "\n",
    "        channel_data = eeg_measurements[:, nth_channel]\n",
    "        for idx_1, idx_2 in zip(idx_condition_1, idx_condition_2):\n",
    "\n",
    "            condition_1_raw[channel_names[nth_channel]].append(channel_data[idx_1:idx_1 + fs * 10])\n",
    "            condition_1_filt[channel_names[nth_channel]].append(signal.lfilter(b, a, signal.sosfilt(sos, channel_data)[idx_1:idx_1 + fs * 10]))\n",
    "\n",
    "            condition_2_raw[channel_names[nth_channel]].append(channel_data[idx_2:idx_2 + fs * 10])\n",
    "            condition_2_filt[channel_names[nth_channel]].append(signal.lfilter(b, a, signal.sosfilt(sos, channel_data)[idx_2:idx_2 + fs * 10]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the CSP feature extraction we will use a function from the mne library which contains multiple functions for the processing and feature extraction of EEG data. Even though the documentation specifies that the fit_transform function expects the data to be 2D, this function calls another function which is called fit which needs the data to be 3D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the shape of the data is nchannels, ntrials, nsamples so the data needs to be transposed ntrials, nchannels, nsamples\n",
    "x_condition_1_filt = np.array([condition_1_filt[channel] for channel in channel_names]).transpose(1, 0, 2)\n",
    "# needs to have the same length\n",
    "y_condition_1_filt = np.zeros(x_condition_1_filt.shape[0])\n",
    "\n",
    "x_condition_2_filt = np.array([condition_2_filt[channel] for channel in channel_names]).transpose(1, 0, 2)\n",
    "y_condition_2_filt = np.ones(x_condition_2_filt.shape[0])\n",
    "\n",
    "x_condition_1_raw = np.array([condition_1_raw[channel] for channel in channel_names]).transpose(1, 0, 2)\n",
    "y_condition_1_raw = np.zeros(x_condition_1_raw.shape[0])\n",
    "\n",
    "x_condition_2_raw = np.array([condition_2_raw[channel] for channel in channel_names]).transpose(1, 0, 2)\n",
    "y_condition_2_raw = np.ones(x_condition_2_raw.shape[0])\n",
    "\n",
    "X_train_filt = np.concatenate([x_condition_1_filt, x_condition_2_filt])\n",
    "y_train_filt = np.concatenate([y_condition_1_filt, y_condition_2_filt])\n",
    "\n",
    "X_train_raw = np.concatenate([x_condition_1_raw, x_condition_2_raw])\n",
    "y_train_raw = np.concatenate([y_condition_1_raw, y_condition_2_raw])\n",
    "\n",
    "n_components = 2\n",
    "csp_model = CSP(n_components=n_components, reg=None, log=None, norm_trace=False)\n",
    "\n",
    "# # returns n_samples, n_features_new\n",
    "x_train_csp_filt = csp_model.fit_transform(X_train_filt, y_train_filt)\n",
    "x_train_csp_raw = csp_model.fit_transform(X_train_raw, y_train_raw)\n",
    "\n",
    "# class 0\n",
    "plt.scatter(x_train_csp_filt[:, 0][y_train_filt == 0], x_train_csp_filt[:, 1][y_train_filt == 0], label='eyes closed')\n",
    "# class 1\n",
    "plt.scatter(x_train_csp_filt[:, 0][y_train_filt == 1], x_train_csp_filt[:, 1][y_train_filt == 1], alpha=0.7, label='eyes open')\n",
    "plt.title('The different classes after CSP feature extraction with the filtered data')\n",
    "plt.xlabel('component 1')\n",
    "plt.ylabel('component 2')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# class 0\n",
    "plt.scatter(x_train_csp_raw[:, 0][y_train_raw == 0], x_train_csp_raw[:, 1][y_train_raw == 0], label='eyes closed')\n",
    "# class 1\n",
    "plt.scatter(x_train_csp_raw[:, 0][y_train_raw == 1], x_train_csp_raw[:, 1][y_train_raw == 1], alpha=0.3, label='eyes open')\n",
    "plt.title('The different classes after CSP feature extraction with the raw data')\n",
    "plt.xlabel('component 1')\n",
    "plt.ylabel('component 2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting a random state so the experiment can be replicated\n",
    "X_train_filt_s, X_test_filt_s, y_train_filt_s, y_test_filt_s = train_test_split(X_train_filt, y_train_filt, test_size=0.2, shuffle=True)\n",
    "X_train_raw_s, X_test_raw_s, y_train_raw_s, y_test_raw_s = train_test_split(X_train_raw, y_train_raw, test_size=0.2, shuffle=True)\n",
    "\n",
    "X_train_csp_filt = csp_model.fit_transform(X_train_filt_s, y_train_filt_s)\n",
    "# class 0\n",
    "plt.scatter(X_train_csp_filt[:, 0][y_train_filt_s == 0], X_train_csp_filt[:, 1][y_train_filt_s == 0], label='eyes closed')\n",
    "# class 1\n",
    "plt.scatter(X_train_csp_filt[:, 0][y_train_filt_s == 1], X_train_csp_filt[:, 1][y_train_filt_s == 1], alpha=0.7, label='eyes open')\n",
    "plt.title('Training set with the filtered data')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "X_train_csp_raw = csp_model.fit_transform(X_train_raw_s, y_train_raw_s)\n",
    "# class 0\n",
    "plt.scatter(X_train_csp_raw[:, 0][y_train_raw_s == 0], X_train_csp_raw[:, 1][y_train_raw_s == 0], label='eyes closed')\n",
    "# class 1\n",
    "plt.scatter(X_train_csp_raw[:, 0][y_train_raw_s == 1], X_train_csp_raw[:, 1][y_train_raw_s == 1], alpha=0.3, label='eyes open')\n",
    "plt.title('Training set with the raw data')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "X_test_csp_filt = csp_model.fit_transform(X_test_filt_s, y_test_filt_s)\n",
    "# class 0\n",
    "plt.scatter(X_test_csp_filt[:, 0][y_test_filt_s == 0], X_test_csp_filt[:, 1][y_test_filt_s == 0], label='eyes closed')\n",
    "# class 1\n",
    "plt.scatter(X_test_csp_filt[:, 0][y_test_filt_s == 1], X_test_csp_filt[:, 1][y_test_filt_s == 1], alpha=0.7, label='eyes open')\n",
    "plt.title('Test set with the filtered data')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "X_test_csp_raw = csp_model.fit_transform(X_test_raw_s, y_test_raw_s)\n",
    "# class 0\n",
    "plt.scatter(X_test_csp_raw[:, 0][y_test_raw_s == 0], X_test_csp_raw[:, 1][y_test_raw_s == 0], label='eyes closed')\n",
    "# class 1\n",
    "plt.scatter(X_test_csp_raw[:, 0][y_test_raw_s == 1], X_test_csp_raw[:, 1][y_test_raw_s == 1], alpha=0.7, label='eyes open')\n",
    "plt.title('Test set with the raw data')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are calculating the accuracy of the filtered model and the unfiltered model. The accuracy is calculated by dividing the number of correct predictions by the total number of predictions. The accuracy of the filtered model is higher than the accuracy of the unfiltered model. This is because the filtered model has less noise in the data. So the model can make better predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the accuracy, we will use three different classification methods. These methods are Knn (K nearest neighbors), SVM (Support Vector Machines) and LDA (Linear Discriminant Analysis). These methods are used to classify the EEG data. The Knn method is a method that classifies the data based on the nearest neighbors. The SVM method is a method that classifies the data based on a hyperplane. The LDA method is a method that classifies the data based on the linear combination of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(kernel='linear')\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "svm.fit(X_train_csp_filt, y_train_filt_s)\n",
    "svm_test_predictions = svm.predict(X_test_csp_filt)\n",
    "print(\"Accuracy SVM filtered: \", accuracy_score(y_test_filt_s, svm_test_predictions))\n",
    "\n",
    "svm.fit(X_train_csp_raw, y_train_raw_s)\n",
    "svm_test_predictions = svm.predict(X_test_csp_raw)\n",
    "print(\"Accuracy SVM raw: \", accuracy_score(y_test_raw_s, svm_test_predictions))\n",
    "\n",
    "lda.fit(X_train_csp_filt, y_train_filt_s)\n",
    "lda_test_predictions = lda.predict(X_test_csp_filt)\n",
    "print(\"Accuracy LDA filtered: \", accuracy_score(y_test_filt_s, lda_test_predictions))\n",
    "\n",
    "lda.fit(X_train_csp_raw, y_train_raw_s)\n",
    "lda_test_predictions = lda.predict(X_test_csp_raw)\n",
    "print(\"Accuracy LDA raw: \", accuracy_score(y_test_raw_s, lda_test_predictions))\n",
    "\n",
    "knn.fit(X_train_csp_filt, y_train_filt_s)\n",
    "knn_test_predictions = knn.predict(X_test_csp_filt)\n",
    "print(\"Accuracy KNN filtered: \", accuracy_score(y_test_filt_s, knn_test_predictions))\n",
    "\n",
    "knn.fit(X_train_csp_raw, y_train_raw_s)\n",
    "knn_test_predictions = knn.predict(X_test_csp_raw)\n",
    "print(\"Accuracy KNN raw: \", accuracy_score(y_test_raw_s, knn_test_predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "demo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
